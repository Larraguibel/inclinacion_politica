{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from google import genai\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import json\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"\"\n",
    "client = genai.Client(api_key=os.environ[\"GOOGLE_API_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/twinviews-13k.csv')\n",
    "l_list = data.l.to_list()\n",
    "r_list = data.r.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 100   # puedes ajustar (500‚Äì1000 es seguro)\n",
    "MODEL_NAME = \"text-embedding-004\"\n",
    "SLEEP_TIME = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_texts_in_batches(texts, model=MODEL_NAME, batch_size=BATCH_SIZE, sleep_time=SLEEP_TIME):\n",
    "    \"\"\"\n",
    "    Genera embeddings por lotes con el modelo de Google AI.\n",
    "    Devuelve una lista de vectores (cada embedding es una lista de floats).\n",
    "    \"\"\"\n",
    "    all_embeddings = []\n",
    "\n",
    "    for i in tqdm(range(0, len(texts), batch_size)):\n",
    "        batch = texts[i:i + batch_size]\n",
    "        try:\n",
    "            response = client.models.embed_content(\n",
    "                model=model,\n",
    "                contents=batch\n",
    "            )\n",
    "            batch_embeddings = [e.values for e in response.embeddings]\n",
    "            all_embeddings.extend(batch_embeddings)\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error en batch {i}-{i+batch_size}: {e}\")\n",
    "            # Esperar unos segundos y reintentar si falla\n",
    "            time.sleep(5)\n",
    "        time.sleep(sleep_time)\n",
    "\n",
    "    return np.array(all_embeddings, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ Generando embeddings para columna L...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 139/139 [05:43<00:00,  2.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Embeddings L guardados: (13855, 768)\n",
      "üîπ Generando embeddings para columna R...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 139/139 [05:21<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings R guardados: (13855, 768)\n",
      "üéØ Proceso completado. Archivos guardados en '../data/'\n"
     ]
    }
   ],
   "source": [
    "print(\"üîπ Generando embeddings para columna L...\")\n",
    "l_embeddings = embed_texts_in_batches(l_list)\n",
    "np.save(\"../data/l_embeddings.npy\", l_embeddings)\n",
    "print(f\"Embeddings L guardados: {l_embeddings.shape}\")\n",
    "\n",
    "print(\"üîπ Generando embeddings para columna R...\")\n",
    "r_embeddings = embed_texts_in_batches(r_list)\n",
    "np.save(\"../data/r_embeddings.npy\", r_embeddings)\n",
    "print(f\"Embeddings R guardados: {r_embeddings.shape}\")\n",
    "\n",
    "print(\"üéØ Proceso completado. Archivos guardados en '../data/'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lo guardamos tambi√©n en formato parquet\n",
    "\n",
    "def save_parquet(texts, embeddings, filename):\n",
    "    df = pd.DataFrame({\n",
    "        \"text\": texts,\n",
    "        \"embedding\": [json.dumps(e.tolist()) for e in embeddings]  # üîß convertimos ndarray ‚Üí list\n",
    "    })\n",
    "    df.to_parquet(filename, compression=\"snappy\")\n",
    "\n",
    "save_parquet(l_list, l_embeddings, \"../data/l_embeddings.parquet\")\n",
    "save_parquet(r_list, r_embeddings, \"../data/r_embeddings.parquet\")\n",
    "\n",
    "# Para cargar\n",
    "#df = pd.read_parquet(\"../data/l_embeddings.parquet\")\n",
    "# df[\"embedding\"] = df[\"embedding\"].apply(json.loads)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
